%Training of CNN

from __future__ import division
#import matplotlib.pyplot as plt

from keras.preprocessing.image import ImageDataGenerator

from PIL import Image
from skimage.io import imread, imsave
from skimage.transform import resize
import pandas
from sklearn.model_selection import train_test_split
import cv2
from random import shuffle
import random
from model import * 
print ("done")
C:\Anaconda3\envs\tensorflow\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
from ._conv import register_converters as _register_converters
Using TensorFlow backend


def read_label_file(image_path, label_path):
    
    path_x = []
    path_y = []
    for i in range(200):
        path_x.append(image_path+str(i)+'.jpg')
        path_y.append(label_path+str(i)+'.png')
    
    return path_x, path_y
def load_image(image_name):
    im = cv2.imread(image_name)
    return cv2.resize(im, (512, 512))

def load_label(image_name):
    im = cv2.imread(image_name)
    im = cv2.resize(im, (512, 512))[:,:,0]
    #print(im)
    #cv2.imwrite('im.jpg', im*255)
    return to_categorical(im, 2)

def batch_generator(data_X, data_y, batch_size):
    n = len(data_X)        
    while True:
        batch_start = 0
        batch_end = batch_size
        indexes = np.arange(len(range(0,n)))
        np.random.shuffle(indexes)
        while batch_start < n:
            limit = min(batch_end, n)
            index = indexes[batch_start:batch_end]
            batch_x = [ data_X[i] for i in index]
            batch_y = [ data_y[i] for i in index]
            
            batch_imagesX  =np.array([load_image(image_name) for image_name in batch_x])
            batch_imagesY  =np.array([load_label(image_name) for image_name in batch_y])
            
            yield(batch_imagesX, batch_imagesY)
            batch_start += batch_size   
            batch_end += batch_size

def load_model(model_name, model):
        try:
            loaded_model = model_from_json(model.to_json())
            # load weights into new model
            loaded_model.load_weights(model_name+'.h5')
            print ('Model loaded')
            model = loaded_model
        except:
            print ('Model not loaded, may be not found')
        return model

image_path = 'C:/Users/Usman Gulshan/Downloads/New_report/images_2017/images_2017/Img'
label_path = 'C:/Users/Usman Gulshan/Downloads/New_report/labels_images_2017/labels_images_2017/Img'

path = 'model'
model_name = 'segmentation'
batch_size = 4

paths_X, paths_y = read_label_file(image_path, label_path)
X_train, X_test, y_train, y_test = train_test_split(paths_X[120:199], paths_y[120:199], test_size=0.2)
train_batch_gen = batch_generator(X_train, y_train, batch_size)
val_batch_gen = batch_generator(X_test, y_test, batch_size)

input_shape=(512,512,3)
model = unet10(input_shape, 2)
#model.summary()
model= load_model(model_name, model)
sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])
#plot_model(model, to_file='model.png')

checkpoint = ModelCheckpoint(model_name+'.h5', monitor='val_loss', verbose=2, save_best_only=True, mode='auto')
#tensorboard = TensorBoard(log_dir='./', batch_size=batch_size, write_graph=True, write_images=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=3, min_lr=0.00001)
earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=2, mode='auto')
cvslogger = keras.callbacks.CSVLogger(model_name+'.csv', separator=',', append=True)
 
nb_epoch = 200
callbacks = [checkpoint, reduce_lr, earlystop, cvslogger]
train_steps = int(len(X_train)//batch_size)
val_steps = int(len(X_test)//batch_size)
with tf.device('/gpu:0'):
    history = model.fit_generator(train_batch_gen,train_steps, epochs=nb_epoch, verbose=1, 
                    max_queue_size=5, validation_data=val_batch_gen, validation_steps= val_steps,shuffle =True,
                    workers=1,use_multiprocessing= False, initial_epoch=0, callbacks=callbacks)

#image, label = val_batch_gen.next()
x, label = train_batch_gen.__next__()
#x = np.array([load_image(paths_X[199])])
pred = model.predict(x) 
print(pred)
pred = np.argmax(pred, axis=3)
#pred = model.predict([image])
for i in range(batch_size):
    cv2.imwrite('input'+str(i)+'.jpg', x[i])
    cv2.imwrite('pred'+str(i)+'.jpg', pred[i]*256)

model.evaluate (x,label)


Coding of CNN model and formulation of 10 layers, and importing relevant libraries.
from __future__ import division


import matplotlib as mpl
import tensorflow as tf

# This line allows mpl to run with no DISPLAY defined
#mpl.use('Agg')
import pandas as pd
import numpy as np
import os

import six
import keras
from keras.models import (Model, Sequential, model_from_json)
from keras.layers import (
    Input,
    Activation,
    Dense,
    Flatten,
    concatenate,
    LSTM, 
    Lambda, 
    Embedding, 
    Reshape,
    TimeDistributed,
    LeakyReLU,
    Dropout
)
from keras.layers.convolutional import (
    Conv2D,
    MaxPooling2D,
    AveragePooling2D,
    Conv1D,
    UpSampling2D,
    Conv2DTranspose
)
from keras.layers.merge import add
from keras.layers.normalization import BatchNormalization
from keras.regularizers import l2
from keras import backend as K
from keras.utils import plot_model

from keras.callbacks import (
    ReduceLROnPlateau, 
    CSVLogger, 
    EarlyStopping, 
    TensorBoard
)
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from keras.callbacks import ModelCheckpoint,TensorBoard,ReduceLROnPlateau
from  keras.utils import to_categorical
from keras.optimizers import Adam, RMSprop, SGD
#from keras_adversarial import AdversarialModel, fix_names, gan_targets, build_gan, simple_gan
#from keras_adversarial import normal_latent_sampling, AdversarialOptimizerSimultaneous
#from keras_adversarial.image_grid_callback import ImageGridCallback
#from keras_adversarial.legacy import l1l2, Dense, fit, fit_generator
#from keras_adversarial.legacy import l1l2, Dense, fit
import keras.backend as K


# =================== UNET ================================================
# https://github.com/jocicmarko/ultrasound-nerve-segmentation/blob/master/train.py

def unet10(input_shape, n_class=1):

    inputs = Input (input_shape)
    #conv0 = Lambda (lambda x: x/255.0 , input_shape = input_shape )(inputs)
    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)

    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
  
    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)
    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    
    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)
    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    
    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)
    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)
    
    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)
    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)
   
    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)
   
    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)
    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)
    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)
   
    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)
    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)

    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)
    
    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)
    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)

    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)
    
    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)
    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)
   
    conv10 = Conv2D(n_class, (1, 1), activation='softmax')(conv9)
    
    model = Model(inputs=[inputs], outputs=[conv10])

    return model
